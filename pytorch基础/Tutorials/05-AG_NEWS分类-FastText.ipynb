{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import torch\n",
    "import torchtext\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1  \\\n",
       "0  3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1  3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "\n",
       "                                                   2  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/ag_news_csv/train.csv', header=None)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   0       120000 non-null  int64 \n",
      " 1   1       120000 non-null  object\n",
      " 2   2       120000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.602858333333334\n",
      "194\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 统计新文的平均字符长度\n",
    "data['length'] = data[2].apply(lambda x: len(x.split(' ')))\n",
    "print(data['length'].mean())\n",
    "print(data['length'].max())\n",
    "print(data['length'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设置\n",
    "NGRAME = 2  # 二元语法\n",
    "MAX_WORDS = 10000   # 最大特征数\n",
    "MAX_LEN = 60\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除语料中的标点符号，并以空格分词\n",
    "tokenizer = lambda x: re.sub('[%s]' % string.punctuation, '', x).split(' ')\n",
    "\n",
    "def filter_low_freq_words(arr, vocab):\n",
    "    \"\"\"过滤掉低词频\"\"\"\n",
    "    arr = [[x if x<MAX_WORDS else 0 for x in example] \n",
    "           for example in arr]\n",
    "    return arr\n",
    "\n",
    "\n",
    "TEXT = torchtext.data.Field(\n",
    "    sequential=True,\n",
    "    tokenize=tokenizer,\n",
    "    lower=True,\n",
    "    fix_length=MAX_LEN,\n",
    "    postprocessing=filter_low_freq_words\n",
    ")\n",
    "\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "train = torchtext.data.TabularDataset(\n",
    "    path='./data/ag_news_csv/train.csv', format='csv',\n",
    "    fields=[(\"label\", LABEL), (\"title\", None), (\"text\", TEXT)],\n",
    "    skip_header=False, csv_reader_params={'delimiter': ','}\n",
    ")\n",
    "\n",
    "train_iter = torchtext.data.BucketIterator(\n",
    "    train, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.text),  \n",
    ")\n",
    "\n",
    "TEXT.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94937\n",
      "<unk>\n",
      "<pad>\n",
      "1\n",
      "20\n",
      "0\n",
      "965\n"
     ]
    }
   ],
   "source": [
    "# 查看词典信息\n",
    "print(len(TEXT.vocab))\n",
    "\n",
    "# index to string\n",
    "print(TEXT.vocab.itos[0])     # unkonwn 未知词\n",
    "print(TEXT.vocab.itos[1])     # padding 填充\n",
    "\n",
    "# string to index\n",
    "print(TEXT.vocab.stoi['<pad>'])\n",
    "print(TEXT.vocab.stoi['it'])\n",
    "\n",
    "# 词频\n",
    "print(TEXT.vocab.freqs['<unk>'])\n",
    "print(TEXT.vocab.freqs['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,  36,  29,  ...,  29,   0, 137],\n",
      "        [  0,   3,   3,  ...,   3,  22,   3],\n",
      "        [ 22,   0,   2,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]])\n",
      "torch.Size([60, 32])\n",
      "tensor([4, 1, 1, 4, 1, 4, 1, 1, 1, 2, 4, 4, 2, 4, 1, 1, 2, 4, 4, 1, 1, 4, 1, 4,\n",
      "        1, 3, 1, 3, 3, 1, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# 查看管道数据信息: text第0维是句子长度\n",
    "for batch in train_iter:\n",
    "    features = batch.text\n",
    "    labels = batch.label\n",
    "    print(features)\n",
    "    print(features.shape)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastText(nn.Module):\n",
    "    \"\"\"\n",
    "    vocab：训练集的字典\n",
    "    vec_dim：词向量的维度\n",
    "    label_size：类别数量\n",
    "    hidden_size：隐藏层神经元数量\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab, v2c_dim, label_size, hidden_size):\n",
    "        super(FastText, self).__init__()\n",
    "        self.embed = nn.Embedding(len(vocab), vec_dim)    # 初始化嵌入层，词典大小和词向量维度\n",
    "        # self.embed.weight.data.copy_(vocab.vectors)       \n",
    "        self.embed.weight.requires_grad = True            # 计算嵌入层梯度\n",
    "        self.fc = nn.Sequential(                          # 序列函数\n",
    "            nn.Linear(vec_dim, hidden_size),              # 线性转换层\n",
    "            nn.BatchNorm1d(hidden_size),                  # 输入通道\n",
    "            nn.ReLU(inplace=True),                        # 线性单元函数作为激活函数\n",
    "            nn.Linear(hidden_size, label_size)            # 再次进行线性转换\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)                                # 将词id转换为对应的词向量\n",
    "        out = self.fc(torch.mean(x, dim=1))              # 这使用torch.mean()将向量进行平均\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText(\n",
      "  (embed): Embedding(94937, 300)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=200, bias=True)\n",
      "    (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Linear(in_features=200, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 对象实例化\n",
    "\n",
    "vec_dim = 300\n",
    "label_size = 4\n",
    "hidden_size = 200\n",
    "\n",
    "model = FastText(TEXT.vocab, vec_dim, label_size, hidden_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data_iter):\n",
    "        self.data_iter = data_iter\n",
    "        # self.length = len(data_iter)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_iter)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.data_iter: \n",
    "            yield (torch.transpose(batch.text, 0, 1),\n",
    "                  torch.unsqueeze(batch.label.float(), dim=1))\n",
    "            \n",
    "            \n",
    "dl_train = DataLoader(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义准确率函数\n",
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = torch.where(\n",
    "        y_pred > 0.5,\n",
    "        torch.ones_like(y_pred, dtype=torch.float32),\n",
    "        torch.zeros_like(y_pred, dtype=torch.float32)\n",
    "    )\n",
    "    acc = torch.mean(1 - torch.abs(y_true - y_pred))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'FastText' object has no attribute 'compile'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-e3a2cfc71eb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.compile(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mloss_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[1;31m# 损失函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# 优化器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmetrics_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 779\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'FastText' object has no attribute 'compile'"
     ]
    }
   ],
   "source": [
    "optimzer = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
