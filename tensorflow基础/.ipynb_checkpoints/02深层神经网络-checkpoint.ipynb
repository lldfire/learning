{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度学习与深层神经网络\n",
    "- 深度学习：通过多层非线性变换对高复杂度数据建模算法的合集\n",
    "- 深层神经网络是实现 “多层非线性变换”最常用的一种方法\n",
    "- 特性：多层 和 非线性\n",
    "- 线性模型具有局限性，使用非线性模型可以解决线性不可分问题\n",
    "\n",
    "#### 激活函数实现去线性化\n",
    "将每个神经元的输出通过一个非线性函数，那么整个神经网络就不再是线性的。神经元输出结果中增加偏置项，然后再使用激活函数。得到输出层的输出\n",
    "\n",
    "常用激活函数：\n",
    "- tf.nn.relu\n",
    "- tf.sigmoind\n",
    "- tf.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用激活函数：\n",
      "[[0.5249792]\n",
      " [0.5249792]\n",
      " [0.5249792]]\n",
      "未使用激活函数\n",
      "[[-0.6053763]\n",
      " [-0.6433336]\n",
      " [-0.7547992]]\n"
     ]
    }
   ],
   "source": [
    "# 使用激活函数实现反向传播算法\n",
    "w1 = tf.Variable(tf.random_normal((2, 3), stddev=1, seed=9))\n",
    "w2 = tf.Variable(tf.random_normal((3, 1), stddev=1, seed=9))\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2], name='x-input')\n",
    "biases1 = -0.5\n",
    "biases2 = 0.1\n",
    "\n",
    "# 使用配置项和激活函数\n",
    "# biases1:配置项\n",
    "a = tf.nn.relu(tf.matmul(x, w1) + biases1)\n",
    "y = tf.sigmoid(tf.matmul(a, w2) + biases2)\n",
    "a2 = tf.matmul(x, w1)\n",
    "y2 = tf.matmul(a2, w2)\n",
    "\n",
    "# 创建会话计算\n",
    "with tf.Session() as sess:\n",
    "    # 初始化\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print('使用激活函数：')\n",
    "    print(sess.run(y, feed_dict={x: [[0.7, 0.9], [0.1, 0.4], [0.5, 0.8]]}))\n",
    "    print('未使用激活函数')\n",
    "    print(sess.run(y2, feed_dict={x: [[0.7, 0.9], [0.1, 0.4], [0.5, 0.8]]}))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多层网络解决异或运算\n",
    "1. 感知机可以简单的理解为单层神经网络，感知机会先将输入进行加权和，然后通过激活函数输出\n",
    "2. 异或运算：两个输入符号相同时，输出0，否则输出1\n",
    "3. 深层神经网络有组合特征提取的功能，神经网络中加入隐藏层就能很好的解决异或文图\n",
    "\n",
    "### 损失函数定义\n",
    "- 神经网络模型的效果及优化的目标时通过损失函数定义的\n",
    "\n",
    "#### 经典损失函数\n",
    "1. 神经网络解决多分类问题最常用方法时设置 $n$ 个输出节点，n 为类别个数，对于每个样例神经网络得到一个n维数组作为输出，如果一个样本属于 k 类别，那么此类别对应的输出节点输出值为1，其他节点输出为0。\n",
    "2. 判断输出向量和期望向量的接近程度：交叉熵 是常用的评判方法之一；给定两个概率分布，$p$和$q$,则交叉熵为：\n",
    "$$H(p,q)=-\\sum_x p(x)\\log q(x)$$\n",
    "3. 当事件总数一定的情况下，概率分布函数$p(X=x)$满足：\n",
    "$$\\forall x  p(X=x)\\in [0, 1] 且 \\sum_xp(X=x)=1$$\n",
    "4. Softmax 回归将神经网络向前传播结果变为概率分布；额外的处理层，将神经网络输出变成概率分布。\n",
    "5. 交叉熵刻画的是两个概率分布之间的距离，值越小两个概率值约接近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.4 2.4 3. ]\n",
      " [4.  4.6 4.6]]\n"
     ]
    }
   ],
   "source": [
    "# 交叉熵代码实现\n",
    "#cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "# 其中：\n",
    "# y_ -- 正确结果\n",
    "# y  -- 预测结果\n",
    "# tf.clip_by_value(y, 1e-10, 10) -- 将张量控制在一个范围内，避免无效运算 log0\n",
    "# 如下：将小于2.4的换成2.4， 大于4.6的换成4.6\n",
    "v = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.clip_by_value(v, 2.4, 4.6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "cn",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "cn",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
