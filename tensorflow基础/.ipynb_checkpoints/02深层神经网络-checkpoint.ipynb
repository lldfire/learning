{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 深度学习与深层神经网络\n",
    "- 深度学习：通过多层非线性变换对高复杂度数据建模算法的合集\n",
    "- 深层神经网络是实现 “多层非线性变换”最常用的一种方法\n",
    "- 特性：多层 和 非线性\n",
    "- 线性模型具有局限性，使用非线性模型可以解决线性不可分问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "#### 激活函数实现去线性化\n",
    "将每个神经元的输出通过一个非线性函数，那么整个神经网络就不再是线性的。神经元输出结果中增加偏置项，然后再使用激活函数。得到输出层的输出\n",
    "\n",
    "常用激活函数：\n",
    "- tf.nn.relu\n",
    "- tf.sigmoind  (logistic)\n",
    "- tf.tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\86132\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用激活函数：\n",
      "[[0.5249792]\n",
      " [0.5249792]\n",
      " [0.5249792]]\n",
      "未使用激活函数\n",
      "[[-0.6053763]\n",
      " [-0.6433336]\n",
      " [-0.7547992]]\n"
     ]
    }
   ],
   "source": [
    "# 使用激活函数实现反向传播算法\n",
    "w1 = tf.Variable(tf.random_normal((2, 3), stddev=1, seed=9))\n",
    "w2 = tf.Variable(tf.random_normal((3, 1), stddev=1, seed=9))\n",
    "x = tf.placeholder(tf.float32, shape=[None, 2], name='x-input')\n",
    "biases1 = -0.5\n",
    "biases2 = 0.1\n",
    "\n",
    "# 使用配置项和激活函数\n",
    "# biases1:配置项\n",
    "a = tf.nn.relu(tf.matmul(x, w1) + biases1)\n",
    "y = tf.sigmoid(tf.matmul(a, w2) + biases2)\n",
    "a2 = tf.matmul(x, w1)\n",
    "y2 = tf.matmul(a2, w2)\n",
    "\n",
    "# 创建会话计算\n",
    "with tf.Session() as sess:\n",
    "    # 初始化\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print('使用激活函数：')\n",
    "    print(sess.run(y, feed_dict={x: [[0.7, 0.9], [0.1, 0.4], [0.5, 0.8]]}))\n",
    "    print('未使用激活函数')\n",
    "    print(sess.run(y2, feed_dict={x: [[0.7, 0.9], [0.1, 0.4], [0.5, 0.8]]}))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多层网络解决异或运算\n",
    "1. 感知机可以简单的理解为单层神经网络，感知机会先将输入进行加权和，然后通过激活函数输出\n",
    "2. 异或运算：两个输入符号相同时，输出0，否则输出1\n",
    "3. 深层神经网络有组合特征提取的功能，神经网络中加入隐藏层就能很好的解决异或文图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### 损失函数定义\n",
    "- 神经网络模型的效果及优化的目标时通过损失函数定义的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "#### 经典损失函数\n",
    "1. 神经网络解决多分类问题最常用方法时设置 $n$ 个输出节点，n 为类别个数，对于每个样例神经网络得到一个n维数组作为输出，如果一个样本属于 k 类别，那么此类别对应的输出节点输出值为1，其他节点输出为0。\n",
    "2. 判断输出向量和期望向量的接近程度：交叉熵 是常用的评判方法之一；给定两个概率分布，$p$和$q$,则交叉熵为：\n",
    "$$H(p,q)=-\\sum_x p(x)\\log q(x)$$\n",
    "3. 当事件总数一定的情况下，概率分布函数$p(X=x)$满足：\n",
    "$$\\forall x  p(X=x)\\in [0, 1] 且 \\sum_xp(X=x)=1$$\n",
    "4. Softmax 回归将神经网络向前传播结果变为概率分布；额外的处理层，将神经网络输出变成概率分布。\n",
    "5. 交叉熵刻画的是两个概率分布之间的距离，值越小两个概率值约接近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.4 2.4 3. ]\n",
      " [4.  4.6 4.6]]\n",
      "[[0.        0.6931472 1.0986123]\n",
      " [1.3862944 1.609438  1.7917595]]\n",
      "* 相乘\n",
      "[[1. 2.]\n",
      " [4. 5.]]\n",
      "矩阵相乘\n",
      "[[3. 3.]\n",
      " [9. 9.]]\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "# 交叉熵代码实现\n",
    "#cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))\n",
    "# 其中：\n",
    "# y_ -- 正确结果\n",
    "# y  -- 预测结果\n",
    "\n",
    "# 交叉熵的实现过程中包含4个tensorflow运算：\n",
    "# 1.tf.clip_by_value(y, 1e-10, 10) -- 将张量控制在一个范围内，避免无效运算 log0。\n",
    "\n",
    "# 将小于2.4的换成2.4， 大于4.6的换成4.6，使输出结果在给定的区间内\n",
    "v = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.clip_by_value(v, 2.4, 4.6)))\n",
    "    \n",
    "# 2.tf.log 运算：此运算完成了对张量中所有元素依次求对数的功能\n",
    "    print(sess.run(tf.log(v)))    # 其底为自然数exp\n",
    "    \n",
    "# 3.乘法运算：通过 * 相乘 与 矩阵乘法有区别\n",
    "    v1 = tf.constant([[0.1, 0.2], [0.4, 0.5]])\n",
    "    v2 = tf.constant([[10.0, 10.0], [10.0, 10.0]])\n",
    "    print('* 相乘')     \n",
    "    print(sess.run(v1 * v2))   # 矩阵中对应元素相乘,得到结果\n",
    "    print('矩阵相乘')\n",
    "    print(sess.run(tf.matmul(v1, v2)))   # 对应行乘对应列的和\n",
    "    \n",
    "# 4.以上步骤得到一个 n×m 的矩阵，n为一个batch中样本的数量，m 为类别的数量，将m个\n",
    "# 类别的交叉熵相加，再求n个样例得平均交叉熵，即：tf.reduce_mean 函数\n",
    "    print(sess.run(tf.reduce_mean(v)))   # 对所有元素求平均值\n",
    "    \n",
    "# 交叉熵会和softmax一起使用，因此可通过如下函数,：使用了softmax回归之后得交叉熵\n",
    "# cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回归损失函数\n",
    "1. 交叉熵为解决分类问题稍的回归函数，而回归问题的神经网络只有一个输出节点，这个节点的输出值就是预测值。\n",
    "2. 对于回归问题，常用的损失函数是*均方误差*（MSE）：\n",
    "$$MSE(y, y')=\\frac{\\sum_{i=1}^n(y_i - y'_i)^2}{n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05833337\n"
     ]
    }
   ],
   "source": [
    "# 回归损失函数代码实现\n",
    "y_ = tf.constant([[1.0, 3.0, 4.0], [2.0, 1.0, 5.0]])    # 真实值\n",
    "y = tf.constant([[1.1, 3.2, 4.4], [2.2, 1.1, 5.3]])    # 真实值\n",
    "mse = tf.reduce_mean(tf.square(y_ - y))   # - 两个矩阵中对应的元素相减\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义损失函数\n",
    "1. 目标：使得预测值和真实值间的差距尽量小\n",
    "2. 使用预测商品销量的例子：\n",
    "   - 为了最大化利润，需要综合考虑成本和利润，需要将损失函数和利润联系起来，损失函数刻画的应该是成本。\n",
    "   - 给出如下损失函数：\n",
    "   $$Loss(y, y')=\\sum_{i=1}^n f(y_i, y'_i),   f(x,y)=\\begin{cases}a(x-y)  & x>y \\\\\n",
    "                                                b(y-x) &x \\leq y \\end{cases}$$\n",
    "   - $y_i$为实际结果，$y_i '$为预测结果，a 和 b 是常量，\n",
    "   - 通过代码实现：loss = tf.reduce_sum(tf.where(tf.greater(v1, v2), a * (v1 - v2), b * (v2 - v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1017 12:55:40.051807  7264 deprecation.py:323] From <ipython-input-8-2cf95fa6f465>:8: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n",
      "[4. 3. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "# tf.where 和tf.greater 用法\n",
    "v1 = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "v2 = tf.constant([4, 3, 2, 1], dtype=tf.float32)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.greater(v1, v2)))   # 比较两个张量中的大小，并返回结果\n",
    "    print(sess.run(\n",
    "        tf.where(tf.greater(v1, v2), v1, v2)  \n",
    "    ))\n",
    "    # 三个参数，第一个参数为真，返回第二值；否则返回第三个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.1550728]\n",
      " [-0.4910573]]\n"
     ]
    }
   ],
   "source": [
    "# 实现一个简单的神经网络\n",
    "# 输入 x: 样本特征\n",
    "# 输出 y: 预测商品数量\n",
    "# 求解：求解最优参数，使得损失函数尽可能小\n",
    "batch_size = 8\n",
    "\n",
    "# 输入两个节点，样本数据和真实结果\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name='x_input')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y_input')\n",
    "\n",
    "# 定义一个单层的神经网络向前传播过程\n",
    "w1 = tf.Variable(tf.random_normal((2, 1), stddev=1.0, seed=9))\n",
    "y = tf.matmul(x, w1)\n",
    "\n",
    "# 预测成本，少预测一件的成本是10，多预测一件的成本是1\n",
    "loss_less = 10 \n",
    "loss_more = 1\n",
    "# 损失函数\n",
    "loss = tf.reduce_sum(tf.where(tf.greater(y, y_), \n",
    "                             (y - y_) * loss_more,\n",
    "                             (y_ - y) * loss_less))\n",
    "# 反向传播优化函数\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "# 模拟数据\n",
    "rdm = np.random.RandomState(9)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size, 2)\n",
    "\n",
    "# 加入噪音数据\n",
    "Y = [[x1 + x2 + rdm.rand()/10.0 - 0.05] for x1, x2 in X]\n",
    "\n",
    "# 训练神经网络\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(w1))\n",
    "    for i in range(5000):\n",
    "        start = (i * batch_size) % dataset_size\n",
    "        end = min(start + batch_size, dataset_size)\n",
    "        sess.run(train_step,\n",
    "                 feed_dict={x: X[start:end], y_: Y[start:end]})\n",
    "    w2 = sess.run(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0411468]\n",
      " [1.0336019]]\n",
      "[[0.5295395 ]\n",
      " [0.65449923]\n",
      " [0.37386113]\n",
      " [0.69216627]\n",
      " [0.44462648]]\n"
     ]
    }
   ],
   "source": [
    "# 使用最优参数预测数据\n",
    "w2 = tf.constant(w2, dtype=tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(w2))\n",
    "    x_test = tf.constant(X[:5], dtype=tf.float32)\n",
    "    print(sess.run(tf.matmul(x_test, w2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络优化算法\n",
    "- 梯度下降法（gradient decent）：主要用于优化单个参数取值\n",
    "- 反向传播算法（backpropagation）：在所有的参数上使用梯度下降法，神经网络中的核心算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BP算法\n",
    "- 梯度下降法 参数更新公式：\n",
    "$$\\theta_{n+1} = \\theta_n - \\eta \\frac {\\Delta}{\\Delta\\theta_n} J(\\theta_n)$$\n",
    "- 神经网络训练步骤：\n",
    "   1. 读取小部分数据作为当前训练数据执行反向传播算法\n",
    "   2. 定义神经网络结果和优化算法\n",
    "   3. 训练神经网络，迭代更新参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络进一步优化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 学习率设置\n",
    "- 指数衰减法：先使用较大的学习率，得到一个较优解，然后随着迭代减小学习率\n",
    "- 指数衰减发使用样例，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始学习率为0.1，训练100轮后，学习率乘以0.96\n",
    "\n",
    "global_step = tf.Variable(0)\n",
    "\n",
    "# 使用函数生成学习率\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    0.1, global_step, 100, 0.96, staircase=True)\n",
    "# 使用指数衰减的学习率，将其传入函数中，将自动更新\n",
    "learning_step = tf.train.GradientDescentOptimizer(learning_rate)\\\n",
    "                .minimize(my_loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 过拟合问题\n",
    "- 正则化思想：在损失函数中加入刻画模型复杂度的指标，加入损失函数为$J(\\theta)$，那么不直接优化$J(\\theta)$，而是优化$J(\\theta)+\\lambda R(\\omega)$。\n",
    " $R(\\omega)$刻画的是模型的复杂程度，$\\lambda$是模型复杂损失在总损失上中的占比\n",
    "\n",
    "- 常见的优化函数两种：\n",
    "    1. L1正则化：会让参数变得稀疏，不可导\n",
    "    2. L2正则化：正则化计算公示可导\n",
    "- L1 和 L2正则可以同时使用:$R(\\omega) = \\sum_i \\alpha|\\omega_i| + (1-\\alpha)\\ \\omega_i^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "7.5\n"
     ]
    }
   ],
   "source": [
    "# tensorflow 中使用正则化函数\n",
    "weights = tf.constant([[1.0, -2.0], [-3.0, 4.0]])\n",
    "with tf.Session() as sess:\n",
    "    # 权重的绝对值和(|1| + |-2| + |-3| + |4|) * 0.5 = 5\n",
    "    print(sess.run(tf.contrib.layers.l1_regularizer(.5)(weights)))\n",
    "    # 权重的平方和 （(1^2 + (-2)^2 + (-3)^2 + 4^2)/2） * 0.5 = \n",
    "    print(sess.run(tf.contrib.layers.l2_regularizer(.5)(weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def get_weight(shape, lambda):\n",
    "    # 生成一个变量\n",
    "    var = tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "cn",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "cn",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
